{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22a21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import predict_labels\n",
    "from wettbewerb import load_references, save_predictions\n",
    "import time\n",
    "from score import score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pywt\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from ecgdetectors import Detectors\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import filter_ecgToTest\n",
    "from filter_ecgToTest import filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d058cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\t Dateien wurden geladen.\n"
     ]
    }
   ],
   "source": [
    "ecg_leads, ecg_labels, fs, ecg_names = load_references('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "592c98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ecg_lead in enumerate(ecg_leads):\n",
    "    ecg_leads[idx]=filter(ecg_leads[idx])\n",
    "    ecg_leads[idx]=ecg_lead/np.amax(ecg_leads[idx])\n",
    "    \n",
    "for idx, label in enumerate(ecg_labels):\n",
    "    if label==\"N\":\n",
    "        ecg_labels[idx]=0\n",
    "    if label==\"A\":\n",
    "        ecg_labels[idx]=1\n",
    "    if label==\"O\":\n",
    "        ecg_labels[idx]=2\n",
    "    if label==\"~\":\n",
    "        ecg_labels[idx]=3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b68ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is just to make the binary clasification\n",
    "df=pd.DataFrame(data=dict(lables=ecg_labels))\n",
    "df['ecg_signal']=ecg_leads\n",
    "df = df[df.lables != 'O']\n",
    "df = df[df.lables != '~']\n",
    "ecg_labelsBinary=df.lables.tolist()\n",
    "ecg_leadsBinary=df.ecg_signal.tolist()\n",
    "from sklearn.model_selection import train_test_split\n",
    "#this is only to test our progress by splitting into smaller test data\n",
    "ecg_train, ecg_test, labels_train, labels_test = train_test_split(ecg_leadsBinary, ecg_labelsBinary, test_size=0.2,stratify=ecg_labelsBinary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ba9d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ecg_train, ecg_test, labels_train, labels_test = train_test_split(ecg_leads, ecg_labels, test_size=0.2,stratify=ecg_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbd3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the median length of the sammples\n",
    "lenECG=list()\n",
    "for idx, ecg_lead in enumerate(ecg_train):\n",
    "    lenECG.append(len(ecg_lead))\n",
    "\n",
    "minL=round(np.median(lenECG))\n",
    "ecgTemp=ecg_train\n",
    "for idx, ecg_lead in enumerate(ecg_train):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        labels_train.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_train=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_train[idx]=ecg_lead[0:minL]\n",
    "for idx, ecg_lead in enumerate(ecg_train):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        labels_train.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_train=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_train[idx]=ecg_lead[0:minL]\n",
    "#this transforms the overall data to a matrix form \n",
    "ecg_train=np.vstack(ecg_train)\n",
    "#this is the actual SMOTE part to generate more data\n",
    "#this is the extra data that gets generated with the smote alg\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=888)\n",
    "ecg_train, labels_train = sm.fit_resample(ecg_train, labels_train)\n",
    "#ni idea porque pero me toca correr el code dos veces para que funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a879bb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m ecgTemp\u001b[38;5;241m=\u001b[39mecg_test\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ecg_lead \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ecg_test):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ecg_lead)\u001b[38;5;241m<\u001b[39m\u001b[43mminL\u001b[49m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#removes the signals that are too short\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         ecgTemp\u001b[38;5;241m.\u001b[39mpop(idx)\n\u001b[0;32m      7\u001b[0m         labels_test\u001b[38;5;241m.\u001b[39mpop(idx)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minL' is not defined"
     ]
    }
   ],
   "source": [
    "# esto es para hacer la test data solo de 9000 de largo\n",
    "ecgTemp=ecg_test\n",
    "for idx, ecg_lead in enumerate(ecg_test):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        labels_test.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_test=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_test[idx]=ecg_lead[0:minL]\n",
    "for idx, ecg_lead in enumerate(ecg_test):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        labels_test.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_test=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_test[idx]=ecg_lead[0:minL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbedcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es para hacer la test data solo de 9000 de largo\n",
    "minL=9000\n",
    "ecgTemp=ecg_leads\n",
    "for idx, ecg_lead in enumerate(ecg_leads):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        ecg_labels.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_test=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_leads[idx]=ecg_lead[0:minL]\n",
    "for idx, ecg_lead in enumerate(ecg_leads):\n",
    "    if len(ecg_lead)<minL:\n",
    "        #removes the signals that are too short\n",
    "        ecgTemp.pop(idx)\n",
    "        ecg_labels.pop(idx)\n",
    "#makes the signals be the same length\n",
    "ecg_test=ecgTemp\n",
    "for idx, ecg_lead in enumerate(ecgTemp):\n",
    "    ecg_leads[idx]=ecg_lead[0:minL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c311baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_test=np.array(ecg_test)\n",
    "ecg_test=ecg_test.reshape((ecg_test.shape[0], ecg_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26cd5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77fe30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(ecg_test)\n",
    "y_test=np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bdcdf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aca vamos a probar deep learning a ver si funciona bien o como es el asunto\n",
    "#teno que mirar que es lo que pasa aca xd\n",
    "ecg_train=np.array(ecg_train)\n",
    "ecg_train = ecg_train.reshape((ecg_train.shape[0], ecg_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97bfe092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n",
    "# Create sequential model \n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "#First CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (x_train.shape[1:])))\n",
    "#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Third CNN layer with 128 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Fourth CNN layer with Max pooling\n",
    "cnn_model.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "#Flatten the output\n",
    "cnn_model.add(Flatten())\n",
    "#Add a dense layer with 256 neurons\n",
    "cnn_model.add(Dense(units = 64, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Add a dense layer with 512 neurons\n",
    "cnn_model.add(Dense(units = 128, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "#Softmax as last layer with five outputs\n",
    "cnn_model.add(Dense(units = 4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85903cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "352e09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(ecg_train)\n",
    "y_train=np.array(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44f0afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 9000, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 9000, 64)          6208      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 9000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4500, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4500, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576000)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                36864064  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 36,903,940\n",
      "Trainable params: 36,903,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac0353a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4274, 9000, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed4ed6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "268/268 [==============================] - 8s 27ms/step - loss: 0.9705 - accuracy: 0.5999 - val_loss: 0.9411 - val_accuracy: 0.6034\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.9248 - accuracy: 0.5997 - val_loss: 0.9306 - val_accuracy: 0.5959\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.7110 - accuracy: 0.6886 - val_loss: 1.1070 - val_accuracy: 0.5304\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.3568 - accuracy: 0.8596 - val_loss: 1.7471 - val_accuracy: 0.5276\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.1274 - accuracy: 0.9567 - val_loss: 2.9961 - val_accuracy: 0.5388\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0797 - accuracy: 0.9787 - val_loss: 3.2533 - val_accuracy: 0.5089\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 4.0671 - val_accuracy: 0.5463\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 4.8666 - val_accuracy: 0.5379\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 5.0756 - val_accuracy: 0.5192\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 0.0331 - accuracy: 0.9932 - val_loss: 4.4029 - val_accuracy: 0.5005\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b85d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNONBI=cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto es para la test data ahora mas tarde\n",
    "plt.hist(labels_test, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3795337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 145ms/step - loss: 2.8622 - accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8622372150421143, 0.844660222530365]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "38d82ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = cnn_model.to_json()\n",
    "with open(\"modelNONBINOSMOTE.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn_model.save_weights(\"modelNONBINOSMOTE.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251b9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "813e8873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 144ms/step - loss: 2.8622 - accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8622372150421143, 0.844660222530365]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "loaded_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f498e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df1ff76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 9000, 32)          128       \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 9000, 64)          6208      \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 9000, 128)         24704     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 4500, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4500, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 576000)            0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                36864064  \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,903,682\n",
      "Trainable params: 36,903,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
